{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3fb239e-58e6-428c-922e-e46ddaf7f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Dataset class\n",
    "class CUB200Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = pd.read_csv(os.path.join(root_dir, 'images.txt'), sep=' ', names=['id', 'filepath'])\n",
    "        self.labels = pd.read_csv(os.path.join(root_dir, 'image_class_labels.txt'), sep=' ', names=['id', 'label'])\n",
    "        self.bboxes = pd.read_csv(os.path.join(root_dir, 'bounding_boxes.txt'), sep=' ', names=['id', 'x', 'y', 'width', 'height'])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, 'images', self.images.iloc[idx]['filepath'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        bbox = self.bboxes.iloc[idx][['x', 'y', 'width', 'height']].values\n",
    "        bbox = torch.tensor(bbox, dtype=torch.float32)\n",
    "        label = self.labels.iloc[idx]['label']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, bbox\n",
    "\n",
    "# Image transformation\n",
    "def cub_transform(image_size=448):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "    return train_transform\n",
    "\n",
    "train_transform = cub_transform()\n",
    "train_dataset = CUB200Dataset(root_dir='CUB_200_2011/CUB_200_2011', transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.load_state_dict(torch.load('cub_pytorch_resnet50.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Adjust threshold for CAM extraction\n",
    "def extract_high_intensity_region(heatmap, threshold=0.7):  # Increased threshold for more focus\n",
    "    _, thresholded = cv2.threshold(heatmap, threshold * heatmap.max(), 255, cv2.THRESH_BINARY)\n",
    "    thresholded = np.uint8(thresholded)\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        return cv2.boundingRect(largest_contour)\n",
    "    return 0, 0, 0, 0  # If no contours are found\n",
    "\n",
    "# GradCAM class\n",
    "import torch.nn.functional as F\n",
    "class GradCAM:\n",
    "    def __init__(self, model, layers):\n",
    "        self.model = model\n",
    "        self.layers = layers\n",
    "        self.gradients = {}\n",
    "        self.feature_maps = {}\n",
    "        self.model.eval()\n",
    "        self.register_hooks()\n",
    "\n",
    "    def save_gradient(self, layer_name):\n",
    "        def hook(module, grad_input, grad_output):\n",
    "            self.gradients[layer_name] = grad_output[0]\n",
    "        return hook\n",
    "\n",
    "    def forward_hook(self, layer_name):\n",
    "        def hook(module, input, output):\n",
    "            self.feature_maps[layer_name] = output\n",
    "        return hook\n",
    "\n",
    "    def register_hooks(self):\n",
    "        for layer_name in self.layers:\n",
    "            layer = dict([*self.model.named_modules()])[layer_name]\n",
    "            layer.register_forward_hook(self.forward_hook(layer_name))\n",
    "            layer.register_full_backward_hook(self.save_gradient(layer_name))\n",
    "\n",
    "    def generate_gradcam(self, input_image, target_class):\n",
    "        model_output = self.model(input_image)\n",
    "        if target_class is None:\n",
    "            target_class = model_output.argmax(dim=1)\n",
    "        \n",
    "        class_loss = model_output[:, target_class]\n",
    "        self.model.zero_grad()\n",
    "        class_loss.backward()\n",
    "\n",
    "        cams = []\n",
    "        for layer_name in self.layers:\n",
    "            gradients = self.gradients[layer_name]\n",
    "            feature_maps = self.feature_maps[layer_name]\n",
    "            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "            for i in range(pooled_gradients.size(0)):\n",
    "                feature_maps[0][i, :, :] *= pooled_gradients[i]\n",
    "            cam = torch.sum(feature_maps[0], dim=0)\n",
    "            cam = torch.relu(cam)\n",
    "            cam = cam - cam.min()\n",
    "            cam = cam / cam.max()\n",
    "            cam = cv2.resize(cam.detach().cpu().numpy(), (input_image.shape[2], input_image.shape[3]))  # Resize to input image size\n",
    "            cams.append(cam)\n",
    "        \n",
    "        # Combine CAMs from multiple layers\n",
    "        combined_cam = np.mean(cams, axis=0)\n",
    "        return combined_cam\n",
    "\n",
    "# Apply colormap on image\n",
    "def apply_colormap_on_image(org_img, cam, alpha=0.8):\n",
    "    # Ensure original image is in the correct format\n",
    "    if org_img.dtype != np.uint8:\n",
    "        org_img = np.uint8(255 * org_img)\n",
    "\n",
    "    # Enhance the CAM contrast\n",
    "    cam = enhance_cam_contrast(cam, 'power', 2)\n",
    "    cam_resized = cv2.resize(cam, (org_img.shape[1], org_img.shape[0]))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
    "\n",
    "    # Check if original image is single channel, convert it to 3 channels\n",
    "    if len(org_img.shape) == 2 or org_img.shape[2] == 1:\n",
    "        org_img = cv2.cvtColor(org_img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Blend the heatmap with the original image\n",
    "    final_image = cv2.addWeighted(org_img, 1 - alpha, heatmap, alpha, 0)\n",
    "    return final_image\n",
    "\n",
    "def enhance_cam_contrast(cam, method='power', factor=2):\n",
    "    if method == 'log':\n",
    "        cam = np.log1p(cam)\n",
    "    elif method == 'power':\n",
    "        cam = np.power(cam, factor)\n",
    "    cam = cam - cam.min()  # Normalize\n",
    "    cam = cam / cam.max()\n",
    "    return cam\n",
    "\n",
    "def apply_clahe(heatmap):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    heatmap_gray = cv2.cvtColor(heatmap, cv2.COLOR_BGR2GRAY)\n",
    "    return clahe.apply(heatmap_gray)\n",
    "\n",
    "# Calculate IoU\n",
    "def calculate_iou(boxA, boxB):\n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
    "    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
    "    \n",
    "    # Compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    \n",
    "    # Compute the area of both the prediction and ground-truth rectangles\n",
    "    boxAArea = (boxA[2] + 1) * (boxA[3] + 1)\n",
    "    boxBArea = (boxB[2] + 1) * (boxB[3] + 1)\n",
    "    \n",
    "    # Compute the intersection over union by taking the intersection area\n",
    "    # and dividing it by the sum of prediction + ground-truth areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "# Visualize GradCAM\n",
    "def visualize_gradcam(image, gt_bbox, cam_bbox, heatmap, iou):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.gca().add_patch(plt.Rectangle((gt_bbox[0], gt_bbox[1]), gt_bbox[2], gt_bbox[3], fill=False, edgecolor='green', linewidth=2))\n",
    "    plt.gca().add_patch(plt.Rectangle((cam_bbox[0], cam_bbox[1]), cam_bbox[2], cam_bbox[3], fill=False, edgecolor='red', linewidth=2))\n",
    "    print(\"Result for GradCAM\")\n",
    "    plt.title(f'Ground Truth and CAM Bounding Box\\nIoU: {iou:.2f}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(heatmap, cmap='jet', alpha=0.8)  # Increased alpha for overlay\n",
    "    plt.title('Heatmap')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize CAM for different layers\n",
    "def visualize_layer_gradcam(model, layers, image, label):\n",
    "    fig, axs = plt.subplots(1, len(layers), figsize=(15, 5))\n",
    "    for i, layer in enumerate(layers):\n",
    "        grad_cam = GradCAM(model, [layer])\n",
    "        cam = grad_cam.generate_gradcam(image.unsqueeze(0), label)\n",
    "        cam_resized = cv2.resize(cam, (image.shape[2], image.shape[1]))\n",
    "        heatmap = plt.cm.jet(cam_resized)[:, :, :3]\n",
    "        axs[i].imshow(image.permute(1, 2, 0).numpy())\n",
    "        axs[i].imshow(heatmap, alpha=0.5)\n",
    "        axs[i].set_title(f'Layer: {layer}')\n",
    "        axs[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c39f031a-5a73-41ae-9571-a529d6942dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAMPlusPlus(GradCAM):\n",
    "    def generate_gradcamplusplus(self, input_image, target_class):\n",
    "        model_output = self.model(input_image)\n",
    "        if target_class is None:\n",
    "            target_class = model_output.argmax(dim=1)\n",
    "        \n",
    "        class_loss = model_output[:, target_class]\n",
    "        self.model.zero_grad()\n",
    "        class_loss.backward()\n",
    "\n",
    "        cams = []\n",
    "        for layer_name in self.layers:\n",
    "            gradients = self.gradients[layer_name]\n",
    "            feature_maps = self.feature_maps[layer_name]\n",
    "            alpha_num = gradients.pow(2)\n",
    "            alpha_denom = 2 * gradients.pow(2) + torch.sum(feature_maps * gradients.pow(3), dim=[2, 3], keepdim=True)\n",
    "            alpha_denom = torch.where(alpha_denom != 0.0, alpha_denom, torch.ones_like(alpha_denom))\n",
    "            alphas = alpha_num / alpha_denom\n",
    "            weights = torch.relu(gradients)\n",
    "            weights = torch.sum(weights * alphas, dim=[2, 3], keepdim=True)\n",
    "\n",
    "            cam = torch.sum(weights * feature_maps, dim=1).squeeze(0)\n",
    "            cam = torch.relu(cam)\n",
    "            cam = cam - cam.min()\n",
    "            cam = cam / cam.max()\n",
    "            cam = cv2.resize(cam.detach().cpu().numpy(), (input_image.shape[2], input_image.shape[3]))  # Resize to input image size\n",
    "            cams.append(cam)\n",
    "        \n",
    "        combined_cam = np.mean(cams, axis=0)\n",
    "        return combined_cam\n",
    "def visualize_gradcamplusplus(image, gt_bbox, cam_bbox, heatmap, iou):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.gca().add_patch(plt.Rectangle((gt_bbox[0], gt_bbox[1]), gt_bbox[2], gt_bbox[3], fill=False, edgecolor='green', linewidth=2))\n",
    "    plt.gca().add_patch(plt.Rectangle((cam_bbox[0], cam_bbox[1]), cam_bbox[2], cam_bbox[3], fill=False, edgecolor='red', linewidth=2))\n",
    "    print(\"Result for GradCAM++\")\n",
    "    plt.title(f'Ground Truth and CAM Bounding Box\\nIoU: {iou:.2f}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(heatmap, cmap='jet', alpha=0.8)  # Increased alpha for overlay\n",
    "    plt.title('Heatmap')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbf1801a-55e1-433a-bc11-57da78b8639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class ScoreCAM:\n",
    "    def __init__(self, model, layers):\n",
    "        self.model = model\n",
    "        self.layers = layers\n",
    "        self.feature_maps = {}\n",
    "        self.model.eval()\n",
    "        self.register_hooks()\n",
    "\n",
    "    def forward_hook(self, layer_name):\n",
    "        def hook(module, input, output):\n",
    "            self.feature_maps[layer_name] = output\n",
    "        return hook\n",
    "\n",
    "    def register_hooks(self):\n",
    "        for layer_name in self.layers:\n",
    "            layer = dict([*self.model.named_modules()])[layer_name]\n",
    "            layer.register_forward_hook(self.forward_hook(layer_name))\n",
    "\n",
    "    def generate_cam(self, input_image, target_class):\n",
    "        model_output = self.model(input_image)\n",
    "        if target_class is None:\n",
    "            target_class = model_output.argmax(dim=1)\n",
    "\n",
    "        # Get feature maps\n",
    "        feature_maps = [self.feature_maps[layer] for layer in self.layers]\n",
    "\n",
    "        # Get weight for each feature map\n",
    "        weights = []\n",
    "        for layer_name, feature_map in zip(self.layers, feature_maps):\n",
    "            saliency_map = torch.mean(feature_map, dim=1, keepdim=True)\n",
    "            saliency_map = F.interpolate(saliency_map, size=input_image.shape[2:], mode='bilinear', align_corners=False)\n",
    "            norm_saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min() + 1e-5)\n",
    "            output = self.model(input_image * norm_saliency_map)\n",
    "            weights.append(output[0][target_class].item())\n",
    "\n",
    "            # Visualize the saliency map\n",
    "            # plt.imshow(norm_saliency_map.detach().cpu().squeeze(), cmap='jet')\n",
    "            # plt.title(f'Saliency Map for Layer {layer_name}')\n",
    "\n",
    "        # Validate if weights make sense\n",
    "        if not any(weights):\n",
    "            return None\n",
    "\n",
    "        # Calculate weighted sum of feature maps\n",
    "        cam = torch.zeros((input_image.shape[2], input_image.shape[3]), dtype=torch.float32).to(input_image.device)\n",
    "        for i, feature_map in enumerate(feature_maps):\n",
    "            resized_feature_map = F.interpolate(feature_map, size=input_image.shape[2:], mode='bilinear', align_corners=False)\n",
    "            cam += weights[i] * resized_feature_map[0, 0]\n",
    "\n",
    "        # print(f\"CAM before ReLU: {cam}\")\n",
    "\n",
    "        cam = torch.relu(cam)\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / cam.max()\n",
    "\n",
    "        # print(f\"CAM after normalization: {cam}\")\n",
    "\n",
    "        return cam.detach().cpu().numpy()\n",
    "# Visualize ScoreCAM\n",
    "def visualize_scorecam(image, gt_bbox, cam_bbox, heatmap, iou):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.gca().add_patch(plt.Rectangle((gt_bbox[0], gt_bbox[1]), gt_bbox[2], gt_bbox[3], fill=False, edgecolor='green', linewidth=2))\n",
    "    plt.gca().add_patch(plt.Rectangle((cam_bbox[0], cam_bbox[1]), cam_bbox[2], cam_bbox[3], fill=False, edgecolor='red', linewidth=2))\n",
    "    print(\"Result for ScoreCAM\")\n",
    "    plt.title(f'Ground Truth and CAM Bounding Box\\nIoU: {iou:.2f}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(heatmap, cmap='jet', alpha=0.8)  # Increased alpha for overlay\n",
    "    plt.title('Heatmap')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "125c779d-ad50-40c2-8363-538fd03ec141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class LiftCAM:\n",
    "    def __init__(self, model, layers):\n",
    "        self.model = model\n",
    "        self.layers = layers\n",
    "        self.feature_maps = {}\n",
    "        self.model.eval()\n",
    "        self.register_hooks()\n",
    "\n",
    "    def forward_hook(self, layer_name):\n",
    "        def hook(module, input, output):\n",
    "            self.feature_maps[layer_name] = output\n",
    "        return hook\n",
    "\n",
    "    def register_hooks(self):\n",
    "        for layer_name in self.layers:\n",
    "            layer = dict([*self.model.named_modules()])[layer_name]\n",
    "            layer.register_forward_hook(self.forward_hook(layer_name))\n",
    "\n",
    "    def generate_cam(self, input_image, target_class):\n",
    "        model_output = self.model(input_image)\n",
    "        if target_class is None:\n",
    "            target_class = model_output.argmax(dim=1)\n",
    "\n",
    "        # Get feature maps\n",
    "        feature_maps = [self.feature_maps[layer] for layer in self.layers]\n",
    "\n",
    "        # Calculate CAM using feature maps without gradients\n",
    "        cams = []\n",
    "        for feature_map in feature_maps:\n",
    "            cam = torch.mean(feature_map, dim=1, keepdim=True)  # Global average pooling\n",
    "            cam = cam - cam.min()\n",
    "            cam = cam / cam.max()\n",
    "            cam = F.interpolate(cam, size=(input_image.shape[2], input_image.shape[3]), mode='bilinear', align_corners=False)\n",
    "            cams.append(cam.squeeze(0).squeeze(0))\n",
    "\n",
    "        # Combine CAMs from multiple layers\n",
    "        combined_cam = torch.mean(torch.stack(cams), dim=0)\n",
    "        return combined_cam.detach().cpu().numpy()\n",
    "\n",
    "# Visualize LIFT-CAM\n",
    "def visualize_liftcam(image, gt_bbox, cam_bbox, heatmap, iou):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.gca().add_patch(plt.Rectangle((gt_bbox[0], gt_bbox[1]), gt_bbox[2], gt_bbox[3], fill=False, edgecolor='green', linewidth=2))\n",
    "    plt.gca().add_patch(plt.Rectangle((cam_bbox[0], cam_bbox[1]), cam_bbox[2], cam_bbox[3], fill=False, edgecolor='red', linewidth=2))\n",
    "    print(\"Result for LIFT-CAM\")\n",
    "    plt.title(f'Ground Truth and CAM Bounding Box\\nIoU: {iou:.2f}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(heatmap, cmap='jet', alpha=0.8)  # Increased alpha for overlay\n",
    "    plt.title('Heatmap')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb4867c6-600c-48b6-b067-f851f4d29a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGradCAM(GradCAM):\n",
    "    def generate_xgradcam(self, input_image, target_class):\n",
    "        model_output = self.model(input_image)\n",
    "        if target_class is None:\n",
    "            target_class = model_output.argmax(dim=1)\n",
    "        \n",
    "        class_loss = model_output[:, target_class]\n",
    "        self.model.zero_grad()\n",
    "        class_loss.backward()\n",
    "\n",
    "        cams = []\n",
    "        for layer_name in self.layers:\n",
    "            gradients = self.gradients[layer_name]\n",
    "            feature_maps = self.feature_maps[layer_name]\n",
    "            \n",
    "            # Weigh the feature maps by the gradients\n",
    "            weights = torch.mean(gradients, dim=[2, 3], keepdim=True)\n",
    "            weighted_feature_maps = feature_maps * weights\n",
    "            \n",
    "            # XGrad-CAM calculation\n",
    "            cam = torch.sum(weighted_feature_maps, dim=1).squeeze(0)\n",
    "            cam = torch.relu(cam)\n",
    "            cam = cam - cam.min()\n",
    "            cam = cam / cam.max()\n",
    "            cam = cv2.resize(cam.detach().cpu().numpy(), (input_image.shape[2], input_image.shape[3]))  # Resize to input image size\n",
    "            cams.append(cam)\n",
    "        \n",
    "        combined_cam = np.mean(cams, axis=0)\n",
    "        return combined_cam\n",
    "# Visualize XGrad-CAM\n",
    "def visualize_xgradcam(image, gt_bbox, cam_bbox, heatmap, iou):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.gca().add_patch(plt.Rectangle((gt_bbox[0], gt_bbox[1]), gt_bbox[2], gt_bbox[3], fill=False, edgecolor='green', linewidth=2))\n",
    "    plt.gca().add_patch(plt.Rectangle((cam_bbox[0], cam_bbox[1]), cam_bbox[2], cam_bbox[3], fill=False, edgecolor='red', linewidth=2))\n",
    "    print(\"Result for XGrad-CAM\")\n",
    "    plt.title(f'Ground Truth and CAM Bounding Box\\nIoU: {iou:.2f}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(heatmap, cmap='jet', alpha=0.8)  # Increased alpha for overlay\n",
    "    plt.title('Heatmap')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e4a66fe-2e6d-4f20-825e-d9716998927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerCAM(GradCAM):\n",
    "    def generate_layercam(self, input_image, target_class):\n",
    "        model_output = self.model(input_image)\n",
    "        if target_class is None:\n",
    "            target_class = model_output.argmax(dim=1)\n",
    "        \n",
    "        class_loss = model_output[:, target_class]\n",
    "        self.model.zero_grad()\n",
    "        class_loss.backward()\n",
    "\n",
    "        cams = []\n",
    "        for layer_name in self.layers:\n",
    "            gradients = self.gradients[layer_name]\n",
    "            feature_maps = self.feature_maps[layer_name]\n",
    "            \n",
    "            # Compute LayerCAM by element-wise multiplication of gradients and feature maps\n",
    "            cam = gradients * feature_maps\n",
    "            cam = torch.relu(cam)\n",
    "            cam = cam.mean(dim=1).squeeze(0)  # Global average pooling over the channels\n",
    "            \n",
    "            # Normalize the CAM\n",
    "            cam = cam - cam.min()\n",
    "            cam = cam / cam.max()\n",
    "            cam = cv2.resize(cam.detach().cpu().numpy(), (input_image.shape[2], input_image.shape[3]))  # Resize to input image size\n",
    "            cams.append(cam)\n",
    "        \n",
    "        # Combine CAMs from multiple layers\n",
    "        combined_cam = np.mean(cams, axis=0)\n",
    "        return combined_cam\n",
    "# Visualize LayerCAM\n",
    "def visualize_layercam(image, gt_bbox, cam_bbox, heatmap, iou):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.gca().add_patch(plt.Rectangle((gt_bbox[0], gt_bbox[1]), gt_bbox[2], gt_bbox[3], fill=False, edgecolor='green', linewidth=2))\n",
    "    plt.gca().add_patch(plt.Rectangle((cam_bbox[0], cam_bbox[1]), cam_bbox[2], cam_bbox[3], fill=False, edgecolor='red', linewidth=2))\n",
    "    print(\"Result for LayerCAM\")\n",
    "    plt.title(f'Ground Truth and CAM Bounding Box\\nIoU: {iou:.2f}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(heatmap, cmap='jet', alpha=0.8)  # Increased alpha for overlay\n",
    "    plt.title('Heatmap')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e3090c2-3993-42db-abfb-64f41f7c1ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------------------+--------------------+--------------------+\n",
      "|   |  Method   |     Average IoU      |     Precision      |      Accuracy      |\n",
      "+---+-----------+----------------------+--------------------+--------------------+\n",
      "| 0 |  GradCAM  | 0.15978269663763894  | 0.3333333333333333 | 0.3333333333333333 |\n",
      "| 1 | GradCAM++ | 0.30452957659936336  | 0.3333333333333333 | 0.3333333333333333 |\n",
      "| 2 | ScoreCAM  | 0.002099152978973271 |        0.0         |        0.0         |\n",
      "| 3 | LIFT-CAM  | 0.30231168177702883  | 0.3333333333333333 | 0.3333333333333333 |\n",
      "| 4 | XGrad-CAM | 0.15978269663763894  | 0.3333333333333333 | 0.3333333333333333 |\n",
      "| 5 | LayerCAM  |  0.3262461870336211  | 0.6666666666666666 | 0.6666666666666666 |\n",
      "+---+-----------+----------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def display_iou_results(iou_gradcam, iou_gradcam_pp, iou_scorecam, iou_liftcam, iou_xgradcam, iou_layercam):\n",
    "    data = {\n",
    "        'Method': ['GradCAM', 'GradCAM++', 'ScoreCAM', 'LIFT-CAM', 'XGrad-CAM', 'LayerCAM'],\n",
    "        'IoU': [iou_gradcam, iou_gradcam_pp, iou_scorecam, iou_liftcam, iou_xgradcam, iou_layercam]\n",
    "    }\n",
    "    iou_results_df = pd.DataFrame(data)\n",
    "    table = tabulate(iou_results_df, headers='keys', tablefmt='pretty')\n",
    "    print(table)\n",
    "\n",
    "    \n",
    "# Initialize lists to store IoU values for each method\n",
    "iou_gradcam_list = []\n",
    "iou_gradcam_pp_list = []\n",
    "iou_scorecam_list = []\n",
    "iou_liftcam_list = []\n",
    "iou_xgradcam_list = []\n",
    "iou_layercam_list = []\n",
    "\n",
    "layer_names = ['layer1', 'layer2', 'layer3', 'layer4']\n",
    "threshold = 0.3  # Common IoU threshold for true positive detection\n",
    "true_positive_count = {\n",
    "    'GradCAM': 0,\n",
    "    'GradCAM++': 0,\n",
    "    'ScoreCAM': 0,\n",
    "    'LIFT-CAM': 0,\n",
    "    'XGrad-CAM': 0,\n",
    "    'LayerCAM': 0\n",
    "}\n",
    "false_positive_count = {\n",
    "    'GradCAM': 0,\n",
    "    'GradCAM++': 0,\n",
    "    'ScoreCAM': 0,\n",
    "    'LIFT-CAM': 0,\n",
    "    'XGrad-CAM': 0,\n",
    "    'LayerCAM': 0\n",
    "}\n",
    "\n",
    "count = 0\n",
    "for images, labels, bboxes in train_loader:\n",
    "    images, labels, bboxes = images.to(device), labels.to(device), bboxes.to(device)\n",
    "    outputs = model(images)\n",
    "    target_class = labels[0].item()\n",
    "    \n",
    "    # GradCAM\n",
    "    grad_cam = GradCAM(model, layer_names)\n",
    "    cam = grad_cam.generate_gradcam(images, target_class)\n",
    "    cam_bbox = extract_high_intensity_region(cam, threshold=0.5)\n",
    "    gt_bbox = bboxes[0].cpu().numpy()\n",
    "    iou_gradcam = calculate_iou(gt_bbox, cam_bbox)\n",
    "    iou_gradcam_list.append(iou_gradcam)\n",
    "    if iou_gradcam >= threshold:\n",
    "        true_positive_count['GradCAM'] += 1\n",
    "    else:\n",
    "        false_positive_count['GradCAM'] += 1\n",
    "\n",
    "    # GradCAM++\n",
    "    grad_cam_pp = GradCAMPlusPlus(model, layer_names)\n",
    "    cam_pp = grad_cam_pp.generate_gradcamplusplus(images, target_class)\n",
    "    cam_bbox_pp = extract_high_intensity_region(cam_pp, threshold=0.5)\n",
    "    iou_gradcam_pp = calculate_iou(gt_bbox, cam_bbox_pp)\n",
    "    iou_gradcam_pp_list.append(iou_gradcam_pp)\n",
    "    if iou_gradcam_pp >= threshold:\n",
    "        true_positive_count['GradCAM++'] += 1\n",
    "    else:\n",
    "        false_positive_count['GradCAM++'] += 1\n",
    "\n",
    "    # ScoreCAM\n",
    "    score_cam = ScoreCAM(model, layer_names)\n",
    "    cam_sc = score_cam.generate_cam(images, target_class)\n",
    "    if cam_sc is not None:\n",
    "        cam_bbox_sc = extract_high_intensity_region(cam_sc, threshold=0.5)\n",
    "        iou_scorecam = calculate_iou(gt_bbox, cam_bbox_sc)\n",
    "    else:\n",
    "        iou_scorecam = 0.0\n",
    "    iou_scorecam_list.append(iou_scorecam)\n",
    "    if iou_scorecam >= threshold:\n",
    "        true_positive_count['ScoreCAM'] += 1\n",
    "    else:\n",
    "        false_positive_count['ScoreCAM'] += 1\n",
    "\n",
    "    # LIFT-CAM\n",
    "    lift_cam = LiftCAM(model, layer_names)\n",
    "    cam_lift = lift_cam.generate_cam(images, target_class)\n",
    "    cam_bbox_lift = extract_high_intensity_region(cam_lift, threshold=0.5)\n",
    "    iou_liftcam = calculate_iou(gt_bbox, cam_bbox_lift)\n",
    "    iou_liftcam_list.append(iou_liftcam)\n",
    "    if iou_liftcam >= threshold:\n",
    "        true_positive_count['LIFT-CAM'] += 1\n",
    "    else:\n",
    "        false_positive_count['LIFT-CAM'] += 1\n",
    "\n",
    "    # XGrad-CAM\n",
    "    xgrad_cam = XGradCAM(model, layer_names)\n",
    "    cam_xgrad = xgrad_cam.generate_xgradcam(images, target_class)\n",
    "    cam_bbox_xgrad = extract_high_intensity_region(cam_xgrad, threshold=0.5)\n",
    "    iou_xgradcam = calculate_iou(gt_bbox, cam_bbox_xgrad)\n",
    "    iou_xgradcam_list.append(iou_xgradcam)\n",
    "    if iou_xgradcam >= threshold:\n",
    "        true_positive_count['XGrad-CAM'] += 1\n",
    "    else:\n",
    "        false_positive_count['XGrad-CAM'] += 1\n",
    "\n",
    "    # LayerCAM\n",
    "    layer_cam = LayerCAM(model, layer_names)\n",
    "    cam_layer = layer_cam.generate_layercam(images, target_class)\n",
    "    cam_bbox_layer = extract_high_intensity_region(cam_layer, threshold=0.5)\n",
    "    iou_layercam = calculate_iou(gt_bbox, cam_bbox_layer)\n",
    "    iou_layercam_list.append(iou_layercam)\n",
    "    if iou_layercam >= threshold:\n",
    "        true_positive_count['LayerCAM'] += 1\n",
    "    else:\n",
    "        false_positive_count['LayerCAM'] += 1\n",
    "    \n",
    "    # Increment count and check if we have processed 3 images\n",
    "    count += 1\n",
    "    if count == 3:\n",
    "        break\n",
    "\n",
    "# Calculate the average IoU for each method\n",
    "average_iou_gradcam = np.mean(iou_gradcam_list)\n",
    "average_iou_gradcam_pp = np.mean(iou_gradcam_pp_list)\n",
    "average_iou_scorecam = np.mean(iou_scorecam_list)\n",
    "average_iou_liftcam = np.mean(iou_liftcam_list)\n",
    "average_iou_xgradcam = np.mean(iou_xgradcam_list)\n",
    "average_iou_layercam = np.mean(iou_layercam_list)\n",
    "\n",
    "# Calculate Precision and Accuracy\n",
    "precision_gradcam = true_positive_count['GradCAM'] / (true_positive_count['GradCAM'] + false_positive_count['GradCAM'])\n",
    "precision_gradcam_pp = true_positive_count['GradCAM++'] / (true_positive_count['GradCAM++'] + false_positive_count['GradCAM++'])\n",
    "precision_scorecam = true_positive_count['ScoreCAM'] / (true_positive_count['ScoreCAM'] + false_positive_count['ScoreCAM'])\n",
    "precision_liftcam = true_positive_count['LIFT-CAM'] / (true_positive_count['LIFT-CAM'] + false_positive_count['LIFT-CAM'])\n",
    "precision_xgradcam = true_positive_count['XGrad-CAM'] / (true_positive_count['XGrad-CAM'] + false_positive_count['XGrad-CAM'])\n",
    "precision_layercam = true_positive_count['LayerCAM'] / (true_positive_count['LayerCAM'] + false_positive_count['LayerCAM'])\n",
    "\n",
    "accuracy_gradcam = true_positive_count['GradCAM'] / count\n",
    "accuracy_gradcam_pp = true_positive_count['GradCAM++'] / count\n",
    "accuracy_scorecam = true_positive_count['ScoreCAM'] / count\n",
    "accuracy_liftcam = true_positive_count['LIFT-CAM'] / count\n",
    "accuracy_xgradcam = true_positive_count['XGrad-CAM'] / count\n",
    "accuracy_layercam = true_positive_count['LayerCAM'] / count\n",
    "\n",
    "# Display the results\n",
    "data = {\n",
    "    'Method': ['GradCAM', 'GradCAM++', 'ScoreCAM', 'LIFT-CAM', 'XGrad-CAM', 'LayerCAM'],\n",
    "    'Average IoU': [average_iou_gradcam, average_iou_gradcam_pp, average_iou_scorecam, average_iou_liftcam, average_iou_xgradcam, average_iou_layercam],\n",
    "    'Precision': [precision_gradcam, precision_gradcam_pp, precision_scorecam, precision_liftcam, precision_xgradcam, precision_layercam],\n",
    "    'Accuracy': [accuracy_gradcam, accuracy_gradcam_pp, accuracy_scorecam, accuracy_liftcam, accuracy_xgradcam, accuracy_layercam]\n",
    "}\n",
    "iou_results_df = pd.DataFrame(data)\n",
    "table = tabulate(iou_results_df, headers='keys', tablefmt='pretty')\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
